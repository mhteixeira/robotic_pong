{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [PIP-PRoS] Improving the bounce mechanics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import serial\n",
    "import time\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from params import *\n",
    "from helpers import detect_ball, is_ball_inside_field, warp_point\n",
    "\n",
    "file = open(\"../../assets/calibration/calibration.pkl\",'rb')\n",
    "cameraMatrix, dist = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original algorithm and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original parameters\n",
    "moving_average_window_size = 10\n",
    "initializing_window = 5\n",
    "discarted_values = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_target(frame, kf, ball_position, xd_array, yd_array, x_robot_corner, max_width, max_height, y_preds, is_going_to_bounce, current_pred):\n",
    "    top_left_corner = np.array([0, 0])\n",
    "    bottom_right_corner = np.array([max_width, max_height])\n",
    "    \n",
    "    # Kalman predictions\n",
    "    kf.correct(np.array(ball_position, dtype=np.float32))\n",
    "    _, _, xd_pred, yd_pred = kf.predict()\n",
    "    y_pred = current_pred\n",
    "    field_height = (bottom_right_corner[1] - top_left_corner[1])\n",
    "    if xd_pred and yd_pred:\n",
    "        xd_array.append(xd_pred)\n",
    "        yd_array.append(yd_pred)\n",
    "    \n",
    "    if len(xd_array) >= discarted_values + 1:\n",
    "    \n",
    "        if len(xd_array) > moving_average_window_size + initializing_window:\n",
    "            # print(np.array(xd_array[-moving_average_window_size:]).flatten())\n",
    "            xd = np.mean(xd_array[-moving_average_window_size:])\n",
    "            yd = np.mean(yd_array[-moving_average_window_size:])\n",
    "        elif len(xd_array) > initializing_window:\n",
    "            # print(np.array(xd_array[initializing_window:]).flatten())\n",
    "            xd = np.mean(xd_array[initializing_window:])\n",
    "            yd = np.mean(yd_array[initializing_window:])\n",
    "        else:\n",
    "            xd = np.mean(xd_array)\n",
    "            yd = np.mean(yd_array)\n",
    "            \n",
    "        slope = round(yd/xd, 2)\n",
    "        if xd > 0 and (xd > 0.2 or abs(yd) > 0.2):\n",
    "            initial_y_pred = slope*(x_robot_corner-ball_position[0]) + ball_position[1]\n",
    "            is_going_to_bounce = not (bottom_right_corner[1] > initial_y_pred > top_left_corner[1])\n",
    "            if initial_y_pred < top_left_corner[1]:\n",
    "                overshoot_y = abs(top_left_corner[1] - initial_y_pred)\n",
    "                number_of_refletions = np.ceil(overshoot_y / field_height).astype(int)\n",
    "                if number_of_refletions <= max_number_of_refletions:\n",
    "                    if (number_of_refletions % 2 == 1):\n",
    "                        y_pred = top_left_corner[1] + (overshoot_y % field_height)\n",
    "                    if (number_of_refletions % 2 == 0):\n",
    "                        y_pred = bottom_right_corner[1] - overshoot_y % field_height\n",
    "                    current_x = ball_position[0]\n",
    "                    next_x = ball_position[0]\n",
    "                    current_y = ball_position[1]\n",
    "                    next_y = ball_position[1]\n",
    "                    for n in range(1, number_of_refletions + 1):\n",
    "                        if n % 2 == 1:\n",
    "                            next_x = (top_left_corner[1] - current_y)/slope + current_x\n",
    "                            next_y = top_left_corner[1]\n",
    "                            cv2.line(frame, (int(current_x), int(current_y)), (int(next_x), top_left_corner[1]), predict_line_color, 1)     \n",
    "                        if n % 2 == 0:\n",
    "                            next_x = -(bottom_right_corner[1] - current_y)/slope + current_x\n",
    "                            next_y = bottom_right_corner[1]\n",
    "                            image = cv2.line(frame, (int(current_x), int(current_y)), (int(next_x), bottom_right_corner[1]), predict_line_color, 1)     \n",
    "                        current_x = next_x\n",
    "                        current_y = next_y\n",
    "                    image = cv2.line(frame, (int(current_x), int(current_y)), (int(x_robot_corner), int(y_pred)), predict_line_color, 1)     \n",
    "            \n",
    "            elif initial_y_pred > bottom_right_corner[1]:\n",
    "                overshoot_y = abs(initial_y_pred - bottom_right_corner[1])\n",
    "                number_of_refletions = np.ceil(abs(overshoot_y / field_height)).astype(int)\n",
    "                \n",
    "                if number_of_refletions <= max_number_of_refletions:\n",
    "                    if (number_of_refletions % 2 == 1):\n",
    "                        y_pred = bottom_right_corner[1] - (overshoot_y % field_height)\n",
    "                    if (number_of_refletions % 2 == 0):\n",
    "                        y_pred = overshoot_y % field_height + top_left_corner[1]\n",
    "                    current_x = ball_position[0]\n",
    "                    next_x = ball_position[0]\n",
    "                    current_y = ball_position[1]\n",
    "                    next_y = ball_position[1]\n",
    "                    for n in range(1, number_of_refletions + 1):\n",
    "                        if n % 2 == 1:\n",
    "                            next_x = (bottom_right_corner[1] - current_y)/slope + current_x\n",
    "                            next_y = bottom_right_corner[1]\n",
    "                            cv2.line(frame, (int(current_x), int(current_y)), (int(next_x), bottom_right_corner[1]), predict_line_color, 1)     \n",
    "                        if n % 2 == 0:\n",
    "                            next_x = -(top_left_corner[1] - current_y)/slope + current_x\n",
    "                            next_y = top_left_corner[1]\n",
    "                            image = cv2.line(frame, (int(current_x), int(current_y)), (int(next_x), top_left_corner[1]), predict_line_color, 1)     \n",
    "                        current_x = next_x\n",
    "                        current_y = next_y\n",
    "                    image = cv2.line(frame, (int(current_x), int(current_y)), (int(x_robot_corner), int(y_pred)), predict_line_color, 1)     \n",
    "            else:\n",
    "                y_pred = initial_y_pred\n",
    "                image = cv2.line(frame, (int(ball_position[0]), int(ball_position[1])), (int(x_robot_corner), int(y_pred)), predict_line_color, 1) \n",
    "        if xd < 0:\n",
    "            xd_array = []\n",
    "            yd_array = []\n",
    "            y_preds = []\n",
    "    \n",
    "    return frame, y_pred, xd_pred, yd_pred, is_going_to_bounce\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that runs the program for a specified file and record the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(filename, predict_function):\n",
    "\tcap = cv2.VideoCapture(filename)\n",
    "\tframe_ball_detection = 0\n",
    "\tframe_first_prediction = 0\n",
    "\twas_ball_detected = False\n",
    "\tframe = None\n",
    "\tif (cap.isOpened()== False): \n",
    "\t\tprint(\"Error opening video stream or file\")\n",
    "\telse:\n",
    "\t\tfor _ in range(2):\n",
    "\t\t\tret, frame = cap.read()\n",
    "\t\th, w, _ = frame.shape\n",
    "\n",
    "\t# Undistorting the frame\n",
    "\tnewCameraMatrix, roi = cv2.getOptimalNewCameraMatrix(cameraMatrix, dist, (w,h), 1, (w,h))\n",
    "\tdst = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "\tframe = dst[roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]]\n",
    "\n",
    "\n",
    "\tfield_delimited = False\n",
    "\n",
    "\t# Transformation matrix for the homography\n",
    "\tM = None\n",
    "\tIM = None # The inverse of M\n",
    "\tmax_width = None\n",
    "\tmax_height = None\n",
    "\n",
    "\t# Relevant corners for the homography\n",
    "\tcorners, ids = None, None\n",
    "\ttop_left_corner = None\n",
    "\tbottom_right_corner = None\n",
    "\ttop_right_corner = None\n",
    "\tbottom_left_corner = None\n",
    "\n",
    "\t# Configuring the ArUco detector\n",
    "\taruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "\tparameters =  cv2.aruco.DetectorParameters()\n",
    "\tdetector = cv2.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "\twhile not field_delimited:\n",
    "\t\tsucces, frame = cap.read()\n",
    "\n",
    "\t\t# Undistorting the frame from the camera\n",
    "\t\t# dst = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "\t\t# frame = dst[roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]]\n",
    "\t\toutput_frame = frame.copy()\n",
    "\n",
    "\t\t# First we make the image monochromatic\n",
    "\t\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t\t# Then we detect the arucos\n",
    "\t\tcorners, ids, rejectedImgPoints = detector.detectMarkers(gray)\n",
    "\t\tframe_markers = cv2.aruco.drawDetectedMarkers(frame.copy(), corners, ids)\n",
    "\t\tcorners = np.array(corners, dtype=int)\n",
    "\n",
    "\t\t# We now check if the amount of detected ArUcos is the expected one\n",
    "\t\t# If it is not, the detection failed\n",
    "\t\tif len(corners) == 4:\n",
    "\t\t\tfield_delimited = True\n",
    "\t\t\t# The top left corner is identified by the Aruco with ID = 0\n",
    "\t\t\ttop_left_corner_id = np.where(ids == 0)[0]\n",
    "\t\t\t\n",
    "\t\t\t# The bottom right corner is identified by the Aruco with ID = 2\n",
    "\t\t\tbottom_right_corner_id = np.where(ids == 2)[0]\n",
    "\n",
    "\t\t\t# The bottom right corner is identified by the Aruco with ID = 3\n",
    "\t\t\ttop_right_corner_id = np.where(ids == 4)[0]\n",
    "\n",
    "\t\t\t# The bottom right corner is identified by the Aruco with ID = 1\n",
    "\t\t\tbottom_left_corner_id = np.where(ids == 1)[0]\n",
    "\n",
    "\t\t\ttop_left_corner = corners[top_left_corner_id][0][0][0]\n",
    "\t\t\tbottom_right_corner = corners[bottom_right_corner_id][0][0][0]\n",
    "\t\t\ttop_right_corner = corners[top_right_corner_id][0][0][0]\n",
    "\t\t\tbottom_left_corner = corners[bottom_left_corner_id][0][0][0]\n",
    "\n",
    "\t\t\twidth_top = np.hypot(\n",
    "\t\t\t\ttop_left_corner[0] - top_right_corner[0], \n",
    "\t\t\t\ttop_left_corner[1] - top_right_corner[1])\n",
    "\t\t\twidth_bottom = np.hypot(\n",
    "\t\t\t\tbottom_left_corner[0] - bottom_right_corner[0], \n",
    "\t\t\t\tbottom_left_corner[1] - bottom_right_corner[1])\n",
    "\t\t\tmax_width = max(int(width_top), int(width_bottom))\n",
    "\t\t\t\n",
    "\t\t\theight_left = np.hypot(\n",
    "\t\t\t\ttop_left_corner[0] - bottom_left_corner[0], \n",
    "\t\t\t\ttop_left_corner[1] - bottom_left_corner[1])\n",
    "\t\t\theight_right = np.hypot(\n",
    "\t\t\t\ttop_right_corner[0] - bottom_right_corner[0], \n",
    "\t\t\t\ttop_right_corner[1] - bottom_right_corner[1])\n",
    "\t\t\tmax_height = max(int(height_left), int(height_right))\n",
    "\n",
    "\t\t\tinput_pts = np.float32([top_left_corner, \n",
    "\t\t\t\t\t\t\t\t\tbottom_left_corner, \n",
    "\t\t\t\t\t\t\t\t\tbottom_right_corner, \n",
    "\t\t\t\t\t\t\t\t\ttop_right_corner])\n",
    "\t\t\toutput_pts = np.float32([[0, 0],\n",
    "\t\t\t\t\t\t\t\t\t[0, max_height - 1],\n",
    "\t\t\t\t\t\t\t\t\t[max_width - 1, max_height - 1],\n",
    "\t\t\t\t\t\t\t\t\t[max_width - 1, 0]])\n",
    "\n",
    "\t\t\t# Compute the perspective transform M\n",
    "\t\t\tM = cv2.getPerspectiveTransform(input_pts,output_pts)\n",
    "\t\t\t_, IM = cv2.invert(M)\n",
    "\t\t\n",
    "\t\toutput_frame = cv2.cvtColor(frame_markers, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t# Variables to deal with the movement prediction\n",
    "\tis_going_to_bounce = False\n",
    "\txd_array = []\n",
    "\tyd_array = []\n",
    "\ty_preds = []\n",
    "\tcurrent_frame = 0\n",
    "\ty_pred = max_height/2\n",
    "\tx_robot_corner = max_width\n",
    "\tprevious_y_robot = None\n",
    "\n",
    "\t# Kalman filter\n",
    "\tkf = cv2.KalmanFilter(4, 2)\n",
    "\tkf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "\tkf.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "\n",
    "\twhile True:\n",
    "\t\tsuccess, frame = cap.read()\n",
    "\t\tif not success: \n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tcurrent_frame+=1\n",
    "\t\t# dst = cv2.undistort(frame, cameraMatrix, dist, None, newCameraMatrix)\n",
    "\t\t# frame = dst[roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]]\n",
    "\t\toutput_frame = frame.copy()\n",
    "\t\t\n",
    "\t\t# Entering homography frame \n",
    "\t\th, w, _ = frame.shape\n",
    "\t\thomography = cv2.warpPerspective(frame,M,(max_width, max_height),flags=cv2.INTER_LINEAR)\n",
    "\t\thomography = cv2.line(homography, (hit_region, 0), (hit_region, max_height), color=(0, 255, 255), thickness=1)\n",
    "\t\t\n",
    "\t\t# Detect the ball\n",
    "\t\tis_ball_detected, _, _, x, y, radius = detect_ball(homography, homography)\n",
    "\t\tif is_ball_detected and not was_ball_detected:\n",
    "\t\t\tframe_ball_detection = current_frame\n",
    "\t\t\twas_ball_detected = True\n",
    "\t\t# Check if the ball is inside the field (close to the wall)\n",
    "\t\tif(is_going_to_bounce):\n",
    "\t\t\tball_inside_field = is_ball_inside_field(x, y, 0, bounce_margin_size, max_width, max_height - bounce_margin_size)\n",
    "\t\telse:\n",
    "\t\t\tball_inside_field = is_ball_inside_field(x, y, 0, 0, max_width, max_height)\n",
    "\t\t\n",
    "\t\t# The prediction only makes sense if the ball is present\n",
    "\t\tif (is_ball_detected and ball_inside_field):\n",
    "\t\t\thomography, y_pred, xd_pred, yd_pred, is_going_to_bounce = predict_function(homography, kf, [x, y], xd_array, yd_array, x_robot_corner, max_width, max_height, y_preds, is_going_to_bounce, y_pred)\n",
    "\t\t\thomography = cv2.arrowedLine(homography, (int(x), int(y)), (int(x+10*xd_pred), int(y+10*yd_pred)), (255, 0, 0), 2) \n",
    "\t\telse:\n",
    "\t\t\txd_array = []\n",
    "\t\t\tyd_array = []\n",
    "\n",
    "\t\tif y_preds != [] and (y_preds[-1] == max_height/2 and y_pred != max_height/2) and frame_first_prediction == 0:\n",
    "\t\t\tframe_first_prediction = current_frame\n",
    "\t\t\n",
    "\t\ty_preds.append(y_pred)\n",
    "\t\ty_robot = y_pred if len(y_preds) > 20 else np.mean(y_preds[-20:])\n",
    "\t\t# if xd_array == []:\n",
    "\t\t# \ty_robot = max_height/2\n",
    "\t\t\t\n",
    "\t\tif not previous_y_robot:\n",
    "\t\t\tprevious_y_robot = y_robot\n",
    "\t\telse:\n",
    "\t\t\tif abs(y_robot - previous_y_robot) > 20:\n",
    "\t\t\t\tposition_percentage = 1 - y_robot/max_height\n",
    "\t\t\t\tprevious_y_robot = y_robot\n",
    "\t\t\t\t\n",
    "\t\tif (is_going_to_bounce):\n",
    "\t\t\thomography = cv2.line(homography, (0, bounce_margin_size),  (max_width, bounce_margin_size), color=(0, 0, 255), thickness=1)\n",
    "\t\t\thomography = cv2.line(homography, (0, max_height - bounce_margin_size), (max_width, max_height - bounce_margin_size), color=(0, 0, 255), thickness=1)\n",
    "\t\t\n",
    "\t\t# Returning to the original frame\n",
    "\t\tinversed_homography = cv2.warpPerspective(homography,IM,(w, h))\n",
    "\t\toutput_frame[inversed_homography != 0] = 0\n",
    "\t\toutput_frame = output_frame + inversed_homography\n",
    "\t\toutput_frame = cv2.line(output_frame, top_left_corner, bottom_left_corner, color=(100, 0, 0), thickness=2)\n",
    "\t\toutput_frame = cv2.line(output_frame, top_left_corner, top_right_corner, color=(100, 0, 0), thickness=2)\n",
    "\t\toutput_frame = cv2.line(output_frame, bottom_right_corner, top_right_corner, color=(100, 0, 0), thickness=2)\n",
    "\t\toutput_frame = cv2.line(output_frame, bottom_right_corner, bottom_left_corner, color=(100, 0, 0), thickness=2)\n",
    "\t\t\n",
    "\t\tx_robot, y_robot = warp_point(int(x_robot_corner), int(y_robot), IM)\n",
    "\t\toutput_frame = cv2.rectangle(output_frame, (int(x_robot - 6), int(y_robot - 30)), (int(x_robot + 6), int(y_robot + 30)), color=(255, 255, 255), thickness=-1)\n",
    "\t\t\n",
    "\t\t# output_frame = cv2.cvtColor(output_frame, cv2.COLOR_BGR2RGB)\n",
    "\t\t\n",
    "\t\tq_pressed = False\n",
    "\t\tcv2.imshow('output_frame', output_frame)\n",
    "\t\twhile True:\n",
    "\t\t\tkey_pressed = cv2.waitKey(1) & 0xFF\n",
    "\t\t\tif key_pressed == ord('a'):\n",
    "\t\t\t\tbreak\n",
    "\t\t\tif key_pressed == ord('q'):\n",
    "\t\t\t\tq_pressed = True\n",
    "\t\t\t\tbreak\n",
    "\t\tif q_pressed:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# When everything done, release the video capture object\n",
    "\tcap.release()\n",
    "\t\n",
    "\t# Closes all the frames\n",
    "\tcv2.destroyAllWindows()\n",
    "\n",
    "\treturn len(y_preds), np.array(y_preds)/max_height, frame_ball_detection, frame_first_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through the discarted values \n",
    "\n",
    "Amount of discarted values at the beggining of the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    './examples\\example16.avi',\n",
    "    './examples\\example17.avi',\n",
    "    './examples\\example18.avi',\n",
    "    './examples\\example19.avi',\n",
    "    './examples\\example20.avi'\n",
    "]\n",
    "for filename in file_list:\n",
    "    n, y_preds, frame_ball_detected, frame_first_prediction = test_prediction(filename, predict_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./examples\\example10.avi\n",
      "./examples\\example11.avi\n",
      "./examples\\example12.avi\n",
      "./examples\\example13.avi\n",
      "./examples\\example15.avi\n",
      "./examples\\example16.avi\n",
      "./examples\\example17.avi\n",
      "./examples\\example18.avi\n",
      "./examples\\example19.avi\n",
      "./examples\\example2.avi\n",
      "./examples\\example20.avi\n",
      "./examples\\example3.avi\n",
      "./examples\\example5.avi\n",
      "./examples\\example6.avi\n",
      "./examples\\example7.avi\n",
      "./examples\\example8.avi\n",
      "./examples\\example9.avi\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob('./examples/*.avi')\n",
    "for filename in file_list:\n",
    "    print(filename)\n",
    "    _ = test_prediction(filename, predict_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
